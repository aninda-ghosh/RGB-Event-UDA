"""
Command: CUDA_VISIBLE_DEVICES=1, python -m evaluation.ncaltech101_evaluation --settings_file config/settings.yaml
             --checkpoint_file <path>

"""
import tqdm
import torch
import argparse
import numpy as np

from config.settings import Settings
from utils.saver import CheckpointSaver
from training.classification_trainer import ClassificationModel


class ClassificationEvaluation(ClassificationModel):
    """Evalutes the output txt file generated by the code provided with the Network Grafting approach"""
    def __init__(self, settings, checkpoint_file):
        self.settings = settings
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        print('For the test evaluation, the parameters for sensor b are taken from the provided yaml file')

        self.getModel()
        self.test_loader_sensor = self.createDataset(self.settings.dataset_name_b,
                                                     self.settings.dataset_path_b,
                                                     self.settings.img_size_b,
                                                     self.settings.batch_size_b,
                                                     self.settings.nr_events_window_b,
                                                     self.settings.event_representation_b,
                                                     self.settings.input_channels_b // 2)


        self.models_dict = {k: v.to(self.device) for k, v in self.models_dict.items()}

        self.saver = CheckpointSaver(save_dir=None)
        self.saver.load_pretrained_weights(self.models_dict, self.weight_list, checkpoint_file=checkpoint_file)


    def getModel(self):
        self.buildModels()
        self.eval_backend = self.models_dict["back_end"]
        self.eval_front = self.models_dict['front_sensor_b']
        self.weight_list = ["front_sensor_b", "front_shared", 'back_end']

    def evaluate(self):
        with torch.no_grad():
            for model in self.models_dict:
                self.models_dict[model].eval()

            val_dataset_length = self.test_loader_sensor.__len__()
            self.pbar = tqdm.tqdm(total=val_dataset_length, unit='Batch', unit_scale=True)

            test_accuracies = []
            for i_batch, sample_batched in enumerate(self.test_loader_sensor):
                test_accuracies = self.testBatchStep(sample_batched, test_accuracies)
                self.pbar.update(1)

        print('Test Accuracy')
        print(np.mean(np.array(test_accuracies).astype(np.float)))

    def testBatchStep(self, sample_batched, test_accuracies):
        sample_batched = [tensor.to(self.device) for tensor in sample_batched]
        data = sample_batched[0]
        labels = sample_batched[1]

        content_features, _, _, _ = self.eval_front(data)
        pred = self.eval_backend(content_features)

        correct_predictions = torch.eq(torch.argmax(pred, dim=-1), labels).detach().cpu().numpy().tolist()
        test_accuracies += correct_predictions

        return test_accuracies

    def getDataloader(self, dataset_name):
        """Returns the dataset loader specified in the settings file"""
        if dataset_name == 'Caltech101_rgb':
            from datasets.caltech101_loader import Caltech101RGB
            return Caltech101RGB
        elif dataset_name == 'Caltech101_gray':
            from datasets.caltech101_loader import Caltech101Gray
            return Caltech101Gray
        elif dataset_name == 'NCaltech101_events':
            from datasets.ncaltech101_loader import NCaltech101Events
            return NCaltech101Events

    def createDataset(self, dataset_name, dataset_path, img_size, batch_size, nr_events_window, event_representation,
                      nr_temporal_bins):
        """
        Creates the validation and the training data based on the provided paths and parameters.
        """
        dataset_builder = self.getDataloader(dataset_name)

        test_dataset = dataset_builder(dataset_path,
                                       height=img_size[0],
                                       width=img_size[1],
                                       nr_events_window=nr_events_window,
                                       augmentation=False,
                                       mode='test',
                                       event_representation=event_representation,
                                       nr_temporal_bins=nr_temporal_bins)

        self.object_classes = test_dataset.class_list

        dataset_loader = torch.utils.data.DataLoader
        test_loader_sensor = dataset_loader(test_dataset, batch_size=batch_size,
                                            num_workers=self.settings.num_cpu_workers,
                                            pin_memory=False, shuffle=True, drop_last=False)

        return test_loader_sensor

def main():
    parser = argparse.ArgumentParser(description='Test network.')
    parser.add_argument('--settings_file', help='Path to settings yaml', required=True)
    parser.add_argument('--checkpoint_file', help='Path to checkpoint file to test', required=True)
    args = parser.parse_args()
    settings_filepath = args.settings_file
    settings = Settings(settings_filepath, generate_log=False)

    evaluator = ClassificationEvaluation(settings, args.checkpoint_file)
    evaluator.evaluate()


if __name__ == "__main__":
    main()